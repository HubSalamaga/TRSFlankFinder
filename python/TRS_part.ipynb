{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cffi\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "from Bio import Entrez\n",
    "import time\n",
    "import argparse\n",
    "import sys\n",
    "from src.SequenceProcessor import SequenceProcessor\n",
    "from src.FileHandler import FileHandler\n",
    "from src.pytrsomix import SeqAnalyzer,TRScalculator\n",
    "from src.stats import Stats\n",
    "from src.BlastProcessor import BLASTProcessor\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fasta_folder_path_name = os.path.basename(\"home/hubert/TRS-omix_new/python/data/E_coli/E_coli\")\n",
    "base_results_directory = os.path.join(os.getcwd(), f\"{input_fasta_folder_path_name}_results\")\n",
    "results_directory = base_results_directory\n",
    "FileHandler.ensure_directory_exists(base_results_directory)\n",
    "name_of_csv_file_storing_TRS_analysis_results = input_fasta_folder_path_name + \"_results.csv\"\n",
    "path_of_folder_storing_TRS_analysis_results = os.path.join(base_results_directory, \"TRS_output\")\n",
    "FileHandler.ensure_directory_exists(path_of_folder_storing_TRS_analysis_results)\n",
    "path_of_csv_file_storing_TRS_analysis_results = os.path.join(path_of_folder_storing_TRS_analysis_results, \n",
    "                                                                 name_of_csv_file_storing_TRS_analysis_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hubert/TRS-omix_new/python/data/E_coli/E_coli/NC_018658.1.fasta\n",
      "Encoded Sequence: b'/home/hubert/TRS-omix_new/python/data/E_coli/E_coli/NC_018658.1.fasta'\n",
      "Encoded TRS: b'/home/hubert/TRS-omix_new/python/data/E_coli/E_coli/trs.txt'\n",
      "Encoded Interiors: b'interiors.txt'\n",
      "/home/hubert/TRS-omix_new/python/data/E_coli/E_coli/NC_011741.1.fasta\n",
      "Encoded Sequence: b'/home/hubert/TRS-omix_new/python/data/E_coli/E_coli/NC_011741.1.fasta'\n",
      "Encoded TRS: b'/home/hubert/TRS-omix_new/python/data/E_coli/E_coli/trs.txt'\n",
      "Encoded Interiors: b'interiors.txt'\n",
      "/home/hubert/TRS-omix_new/python/data/E_coli/E_coli/FM180568.1.fasta\n",
      "Encoded Sequence: b'/home/hubert/TRS-omix_new/python/data/E_coli/E_coli/FM180568.1.fasta'\n",
      "Encoded TRS: b'/home/hubert/TRS-omix_new/python/data/E_coli/E_coli/trs.txt'\n",
      "Encoded Interiors: b'interiors.txt'\n",
      "/home/hubert/TRS-omix_new/python/data/E_coli/E_coli/NC_017626.1.fasta\n",
      "Encoded Sequence: b'/home/hubert/TRS-omix_new/python/data/E_coli/E_coli/NC_017626.1.fasta'\n",
      "Encoded TRS: b'/home/hubert/TRS-omix_new/python/data/E_coli/E_coli/trs.txt'\n",
      "Encoded Interiors: b'interiors.txt'\n",
      "/home/hubert/TRS-omix_new/python/data/E_coli/E_coli/NC_013361.1.fasta\n",
      "Encoded Sequence: b'/home/hubert/TRS-omix_new/python/data/E_coli/E_coli/NC_013361.1.fasta'\n",
      "Encoded TRS: b'/home/hubert/TRS-omix_new/python/data/E_coli/E_coli/trs.txt'\n",
      "Encoded Interiors: b'interiors.txt'\n",
      "/home/hubert/TRS-omix_new/python/data/E_coli/E_coli/NC_011601.1.fasta\n",
      "Encoded Sequence: b'/home/hubert/TRS-omix_new/python/data/E_coli/E_coli/NC_011601.1.fasta'\n",
      "Encoded TRS: b'/home/hubert/TRS-omix_new/python/data/E_coli/E_coli/trs.txt'\n",
      "Encoded Interiors: b'interiors.txt'\n",
      "/home/hubert/TRS-omix_new/python/data/E_coli/E_coli/CP000801.1.fasta\n",
      "Encoded Sequence: b'/home/hubert/TRS-omix_new/python/data/E_coli/E_coli/CP000801.1.fasta'\n",
      "Encoded TRS: b'/home/hubert/TRS-omix_new/python/data/E_coli/E_coli/trs.txt'\n",
      "Encoded Interiors: b'interiors.txt'\n",
      "/home/hubert/TRS-omix_new/python/data/E_coli/E_coli/CP007149.1.fasta\n",
      "Encoded Sequence: b'/home/hubert/TRS-omix_new/python/data/E_coli/E_coli/CP007149.1.fasta'\n",
      "Encoded TRS: b'/home/hubert/TRS-omix_new/python/data/E_coli/E_coli/trs.txt'\n",
      "Encoded Interiors: b'interiors.txt'\n",
      "/home/hubert/TRS-omix_new/python/data/E_coli/E_coli/NZ_CP009644.1.fasta\n",
      "Encoded Sequence: b'/home/hubert/TRS-omix_new/python/data/E_coli/E_coli/NZ_CP009644.1.fasta'\n",
      "Encoded TRS: b'/home/hubert/TRS-omix_new/python/data/E_coli/E_coli/trs.txt'\n",
      "Encoded Interiors: b'interiors.txt'\n",
      "/home/hubert/TRS-omix_new/python/data/E_coli/E_coli/BA000007.2.fasta\n",
      "Encoded Sequence: b'/home/hubert/TRS-omix_new/python/data/E_coli/E_coli/BA000007.2.fasta'\n",
      "Encoded TRS: b'/home/hubert/TRS-omix_new/python/data/E_coli/E_coli/trs.txt'\n",
      "Encoded Interiors: b'interiors.txt'\n",
      "/home/hubert/TRS-omix_new/python/data/E_coli/E_coli/NC_011751.1.fasta\n",
      "Encoded Sequence: b'/home/hubert/TRS-omix_new/python/data/E_coli/E_coli/NC_011751.1.fasta'\n",
      "Encoded TRS: b'/home/hubert/TRS-omix_new/python/data/E_coli/E_coli/trs.txt'\n",
      "Encoded Interiors: b'interiors.txt'\n",
      "/home/hubert/TRS-omix_new/python/data/E_coli/E_coli/NZ_CP076123.1.fasta\n",
      "Encoded Sequence: b'/home/hubert/TRS-omix_new/python/data/E_coli/E_coli/NZ_CP076123.1.fasta'\n",
      "Encoded TRS: b'/home/hubert/TRS-omix_new/python/data/E_coli/E_coli/trs.txt'\n",
      "Encoded Interiors: b'interiors.txt'\n",
      "/home/hubert/TRS-omix_new/python/data/E_coli/E_coli/NC_007946.1.fasta\n",
      "Encoded Sequence: b'/home/hubert/TRS-omix_new/python/data/E_coli/E_coli/NC_007946.1.fasta'\n",
      "Encoded TRS: b'/home/hubert/TRS-omix_new/python/data/E_coli/E_coli/trs.txt'\n",
      "Encoded Interiors: b'interiors.txt'\n",
      "/home/hubert/TRS-omix_new/python/data/E_coli/E_coli/NC_008253.1.fasta\n",
      "Encoded Sequence: b'/home/hubert/TRS-omix_new/python/data/E_coli/E_coli/NC_008253.1.fasta'\n",
      "Encoded TRS: b'/home/hubert/TRS-omix_new/python/data/E_coli/E_coli/trs.txt'\n",
      "Encoded Interiors: b'interiors.txt'\n",
      "/home/hubert/TRS-omix_new/python/data/E_coli/E_coli/NC_004431.1.fasta\n",
      "Encoded Sequence: b'/home/hubert/TRS-omix_new/python/data/E_coli/E_coli/NC_004431.1.fasta'\n",
      "Encoded TRS: b'/home/hubert/TRS-omix_new/python/data/E_coli/E_coli/trs.txt'\n",
      "Encoded Interiors: b'interiors.txt'\n",
      "/home/hubert/TRS-omix_new/python/data/E_coli/E_coli/CP001671.1.fasta\n",
      "Encoded Sequence: b'/home/hubert/TRS-omix_new/python/data/E_coli/E_coli/CP001671.1.fasta'\n",
      "Encoded TRS: b'/home/hubert/TRS-omix_new/python/data/E_coli/E_coli/trs.txt'\n",
      "Encoded Interiors: b'interiors.txt'\n",
      "/home/hubert/TRS-omix_new/python/data/E_coli/E_coli/NC_002655.2.fasta\n",
      "Encoded Sequence: b'/home/hubert/TRS-omix_new/python/data/E_coli/E_coli/NC_002655.2.fasta'\n",
      "Encoded TRS: b'/home/hubert/TRS-omix_new/python/data/E_coli/E_coli/trs.txt'\n",
      "Encoded Interiors: b'interiors.txt'\n"
     ]
    }
   ],
   "source": [
    "input_fasta_folder_path = \"/home/hubert/TRS-omix_new/python/data/E_coli/E_coli\"\n",
    "fasta_files = [f for f in os.listdir(input_fasta_folder_path) if f.endswith('.fasta') or f.endswith('.fa')]\n",
    "trs_calculators = []\n",
    "for fasta_file in fasta_files:\n",
    "            path_to_input_fasta = os.path.join(input_fasta_folder_path, fasta_file)\n",
    "            print(f\"{path_to_input_fasta}\")\n",
    "            if not os.path.exists(path_to_input_fasta):\n",
    "                print(f\"File '{fasta_file}' does not exist! Skipping....\")\n",
    "                continue\n",
    "\n",
    "            # Define the TRS file path\n",
    "            trs_file = os.path.join(input_fasta_folder_path, 'trs.txt').encode('utf-8')\n",
    "            # if not os.path.exists(trs_file):\n",
    "            #     script_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "            #     trs_file = os.path.join(script_dir,'trs.txt')\n",
    "            #     if not os.path.exists(trs_file):\n",
    "            #         print(\"TRS file not found in both input folder and script location! Exiting...\")\n",
    "            #         break\n",
    "\n",
    "            try:\n",
    "                # Initialize TRS calculator for each sequence and perform TRS search\n",
    "                trs_calculator = TRScalculator(sequence=path_to_input_fasta.encode('utf-8'), trs=trs_file, tmin=100, tmax=3000, mode=1)\n",
    "                trs_calculator.calculate()\n",
    "                trs_calculators.append(trs_calculator)\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred while processing '{fasta_file}': {e}\")\n",
    "                continue\n",
    "\n",
    "list_of_trs_results = []\n",
    "\n",
    "for trs_calculator in trs_calculators:\n",
    "    # Extract results from the calculator\n",
    "    result = trs_calculator.Result\n",
    "    # Append the result to the list\n",
    "    list_of_trs_results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe filtered successfully.\n"
     ]
    }
   ],
   "source": [
    "combined_trs_results = pd.concat(list_of_trs_results, ignore_index=True)\n",
    "combined_trs_results[\">SEQ\"] = combined_trs_results[\">SEQ\"].str.replace(\">\",\"\")\n",
    "combined_trs_results\n",
    "combined_trs_results\n",
    "combined_trs_results = SequenceProcessor.extract_sequences(combined_trs_results, 50, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching organism name for id: NC_018658.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hubert/miniconda3/envs/TRS/lib/python3.6/site-packages/Bio/Entrez/__init__.py:670: UserWarning: \n",
      "Email address is not specified.\n",
      "\n",
      "To make use of NCBI's E-utilities, NCBI requires you to specify your\n",
      "email address with each request.  As an example, if your email address\n",
      "is A.N.Other@example.com, you can specify it as follows:\n",
      "   from Bio import Entrez\n",
      "   Entrez.email = 'A.N.Other@example.com'\n",
      "In case of excessive usage of the E-utilities, NCBI will attempt to contact\n",
      "a user at the email address provided before blocking access to the\n",
      "E-utilities.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved organism name for id: NC_018658.1 successfully Escherichia_coli_O104:H4_str._2011C-3493.\n",
      "Fetching organism name for id: NC_011741.1\n",
      "Retrieved organism name for id: NC_011741.1 successfully Escherichia_coli_IAI1.\n",
      "Fetching organism name for id: FM180568.1\n",
      "Retrieved organism name for id: FM180568.1 successfully Escherichia_coli_O127:H6_str._E2348/69.\n",
      "Fetching organism name for id: NC_017626.1\n",
      "Retrieved organism name for id: NC_017626.1 successfully Escherichia_coli_042.\n",
      "Fetching organism name for id: NC_013361.1\n",
      "Retrieved organism name for id: NC_013361.1 successfully Escherichia_coli_O26:H11_str._11368.\n",
      "Fetching organism name for id: NC_011601.1\n",
      "Retrieved organism name for id: NC_011601.1 successfully Escherichia_coli_O127:H6_str._E2348/69.\n",
      "Fetching organism name for id: CP000801.1\n",
      "Retrieved organism name for id: CP000801.1 successfully Escherichia_coli_O139:H28_str._E24377A.\n",
      "Fetching organism name for id: CP007149.1\n",
      "Retrieved organism name for id: CP007149.1 successfully Escherichia_coli_RS218.\n",
      "Fetching organism name for id: NZ_CP009644.1\n",
      "Retrieved organism name for id: NZ_CP009644.1 successfully Escherichia_coli_ER2796.\n",
      "Fetching organism name for id: BA000007.2\n",
      "Retrieved organism name for id: BA000007.2 successfully Escherichia_coli_O157:H7_str._Sakai.\n",
      "Fetching organism name for id: NC_011751.1\n",
      "Retrieved organism name for id: NC_011751.1 successfully Escherichia_coli_UMN026.\n",
      "Fetching organism name for id: NZ_CP076123.1\n",
      "Retrieved organism name for id: NZ_CP076123.1 successfully Escherichia_coli.\n",
      "Fetching organism name for id: NC_007946.1\n",
      "Retrieved organism name for id: NC_007946.1 successfully Escherichia_coli_UTI89.\n",
      "Fetching organism name for id: NC_008253.1\n",
      "Retrieved organism name for id: NC_008253.1 successfully Escherichia_coli_536.\n",
      "Fetching organism name for id: NC_004431.1\n",
      "Retrieved organism name for id: NC_004431.1 successfully Escherichia_coli_CFT073.\n",
      "Fetching organism name for id: CP001671.1\n",
      "Retrieved organism name for id: CP001671.1 successfully Escherichia_coli_ABU_83972.\n",
      "Fetching organism name for id: NC_002655.2\n",
      "Retrieved organism name for id: NC_002655.2 successfully Escherichia_coli_O157:H7_str._EDL933.\n"
     ]
    }
   ],
   "source": [
    "ncbi_ids = combined_trs_results[\"GENOME\"].unique().tolist()\n",
    "if Entrez.email and Entrez.email == 'hsalamaga@ibb.waw.pl' :\n",
    "            print(f\"Email adress is still set to {Entrez.email}\")\n",
    "organism_map = SequenceProcessor.fetch_organism_names(ncbi_ids,email = Entrez.email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_trs_results['Taxonomic Name'] = None\n",
    "combined_trs_results['Taxonomic Name'] = combined_trs_results['GENOME'].map(organism_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_trs_results['L_id'] = combined_trs_results['Taxonomic Name'] + '_L' + combined_trs_results['L-No'].astype(str)\n",
    "combined_trs_results['R_id'] = combined_trs_results['Taxonomic Name'] + '_R' + combined_trs_results['R-No'].astype(str)\n",
    "sequences_df = combined_trs_results[['SEQ_L', 'SEQ_R', 'L_id', 'R_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_directory = 'home/hsalamaga/TRS-omix_new/python/test'\n",
    "path_of_folder_storing_TRS_analysis_results = os.path.join(results_directory, \"TRS_output\")\n",
    "os.makedirs(path_of_folder_storing_TRS_analysis_results, exist_ok=True) \n",
    "fasta_files_with_flanks = os.path.join(path_of_folder_storing_TRS_analysis_results, \"combined_sequences.fasta\")\n",
    "with open(fasta_files_with_flanks, 'w') as fasta_file:\n",
    "        for _, row in sequences_df.iterrows():\n",
    "            # Write left sequence\n",
    "            fasta_file.write(f'>{row[\"L_id\"]}\\n')\n",
    "            fasta_file.write(f'{row[\"SEQ_L\"]}\\n')\n",
    "            # Write right sequence\n",
    "            fasta_file.write(f'>{row[\"R_id\"]}\\n')\n",
    "            fasta_file.write(f'{row[\"SEQ_R\"]}\\n')\n",
    "\n",
    "#Create unique FASTA file with renamed sequences (including ids and L/R identifiers)\n",
    "fasta_files_with_flanks_unique = os.path.join(path_of_folder_storing_TRS_analysis_results, \"combined_sequences_unique.fasta\")\n",
    "#SequenceProcessor.rename_sequences(fasta_files_with_flanks, fasta_files_with_flanks_unique)\n",
    "SequenceProcessor.rename_sequences(fasta_files_with_flanks,fasta_files_with_flanks_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRS proper\n",
    "print(\"Starting analysis...\")   \n",
    "fasta_files = [f for f in os.listdir(input_fasta_folder_path_name) if f.endswith('.fasta') or f.endswith('.fa')]\n",
    "trs_calculators = []\n",
    "\n",
    "# Iterate over each FASTA file to calculate TRS sequences\n",
    "for fasta_file in fasta_files:\n",
    "    path_to_input_fasta = os.path.join(input_fasta_folder_path_name, fasta_file)\n",
    "    print(f\"{path_to_input_fasta}\")\n",
    "    if not os.path.exists(path_to_input_fasta):\n",
    "        print(f\"File '{fasta_file}' does not exist! Skipping....\")\n",
    "        continue\n",
    "\n",
    "    # Define the TRS file path\n",
    "    trs_file = os.path.join(args.input_fasta_folder_path, 'trs.txt').encode('utf-8')\n",
    "    if not os.path.exists(trs_file):\n",
    "        script_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "        trs_file = os.path.join(script_dir,'trs.txt')\n",
    "        if not os.path.exists(trs_file):\n",
    "            print(\"TRS file not found in both input folder and script location! Exiting...\")\n",
    "            break\n",
    "\n",
    "    try:\n",
    "        # Initialize TRS calculator for each sequence and perform TRS search\n",
    "        trs_calculator = TRScalculator(sequence=path_to_input_fasta.encode('utf-8'), trs=trs_file, tmin=args.tmin, tmax=args.tmax, mode=args.mode)\n",
    "        trs_calculator.calculate()\n",
    "        trs_calculators.append(trs_calculator)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing '{fasta_file}': {e}\")\n",
    "        continue\n",
    "\n",
    "list_of_trs_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fixing out of bounds errors \n",
    "results_directory = \"/home/hubert/TRS-omix_new/python/E_coli_results_L100_R100_c1.0/\"\n",
    "combined_results = pd.read_csv(\"/home/hubert/TRS-omix_new/python/E_coli_results_L100_R100_c1.0/TRS_output/E_coli_results.csv\")\n",
    "filtered_fasta_file = FileHandler.find_file_by_name('unique_taxids_not_in_clusters_combined_sequences_unique_blastn_out.txt',folder= results_directory)\n",
    "filtered_fasta_file = filtered_fasta_file[0]\n",
    "#BLASTProcessor.extract_full_TRS_sequences(combined_results,filtered_fasta_file,results_directory,state=1)\n",
    "print(combined_results.shape)\n",
    "#might need to do the entire thing step by step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GET SPECIES INFO\n",
    "combined_results = pd.read_csv(\"/home/hubert/TRS-omix_new/python/klebsiella_results_L100_R100_c0.8/TRS_output/klebsiella_results.csv\")\n",
    "\n",
    "#Set the Entrez e-mail for further processing - seems like for some reason it refuses to remember it a this step and does not pass it into future ncbi requests\n",
    "Entrez.email = SequenceProcessor.validate_and_set_email(email=\"hsalamaga@ibb.waw.pl\")\n",
    "print(f\"Current email is set to {Entrez.email}\")\n",
    "\n",
    "#Fetch taxonomic information for the collected genome IDs\n",
    "ncbi_ids = combined_results[\"GENOME\"].unique().tolist()\n",
    "tax_map = SequenceProcessor.fetch_organism_taxids(ncbi_ids)\n",
    "\n",
    "#Filter and clean the taxonomic mapping\n",
    "filtered_organism_taxid_map = {SequenceProcessor.filter_key_parts(key): value for key, value in tax_map.items()}\n",
    "print(f\"Species - taxid pairs detected in dataset : {filtered_organism_taxid_map}\")\n",
    "\n",
    "#Append taxid information to the filtered map\n",
    "species_info = BLASTProcessor.append_taxids_to_filtered_map(filtered_organism_taxid_map)\n",
    "species_info\n",
    "\n",
    "\n",
    "#numbers assigned do not match the TRS_output file ????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a dictionary of all taxid - acessions pairs in our data\n",
    "modified_blast_path = \"/home/hubert/TRS-omix_new/python/klebsiella_results_L100_R100_c0.8/blast_output/modified_blast/\"\n",
    "nan_file = \"/home/hubert/TRS-omix_new/python/klebsiella_results_L100_R100_c0.8/blast_output/modified_blast/NaN acessions.csv\"\n",
    "results_dict = BLASTProcessor.construct_dict_from_files(modified_blast_path,nan_file)\n",
    "results_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_results = pd.read_csv(\"/home/hubert/TRS-omix_new/python/viruses_results_L100_R100_c0.8/TRS_output/viruses_results.csv\")\n",
    "filtered_fasta_file =\"/home/hubert/TRS-omix_new/python/viruses_results_L100_R100_c0.8/blast_output_2nd_pass/modified_blast/unique_sequences/unique_taxids_full_sequences_blastn_out.txt\"\n",
    "results_directory = \"/home/hubert/TRS-omix_new/python/viruses_results_L100_R100_c0.8/\"\n",
    "full_seq_final = \"/home/hubert/TRS-omix_new/python/klebsiella_results_L100_R100_c0.8/final_results/full_sequences_final.fasta\"\n",
    "#BLASTProcessor.extract_full_TRS_sequences(combined_results,filtered_fasta_file,results_directory,state=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATE NEW CLUSTERS\n",
    "\n",
    "cdhit_clusters_file = \"/home/hubert/TRS-omix_new/python/viruses_results_L100_R100_c0.8/cd-hit-results/combined_sequences_unique_cdhit.clstr\"\n",
    "input_fasta = \"/home/hubert/TRS-omix_new/python/viruses_results_L100_R100_c0.8/TRS_output/combined_sequences_unique.fasta\"\n",
    "output_folder_cluster = \"/home/hubert/TRS-omix_new/python/viruses_results_L100_R100_c0.8/cd-hit-results/fasta_clusters\"\n",
    "results_directory = '/home/hubert/TRS-omix_new/python/klebsiella_results_L100_R100_c0.8/'\n",
    "FileHandler.create_fasta_for_all_clusters(cdhit_clusters_file, input_fasta, output_folder_cluster, create_individual_files=True)\n",
    "#test = create_trs_class_dataframe(output_folder_cluster)\n",
    "#test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GENERTATE ADDITIONAL PLOTS\n",
    "results_directory = \"/home/hubert/TRS-omix_new/python/klebsiella_results_L100_R100_c0.8\"\n",
    "fasta_files_for_plotting = FileHandler.search_for_files(results_directory,'*.fasta')\n",
    "fasta_files_for_plotting_names = FileHandler.extract_file_names(fasta_files_for_plotting)\n",
    "print(f\"Following fasta files were found in {results_directory} : {fasta_files_for_plotting_names}\")\n",
    "statistics = Stats()\n",
    "for fasta_path in fasta_files_for_plotting:\n",
    "    statistics.count_L_R(fasta_path)\n",
    "file_paths = [file_path for file_path in fasta_files_for_plotting if file_path in statistics.file_info]\n",
    "names_to_filter = [\"full_sequences_final.fasta\"]\n",
    "file_paths = [file_path for file_path in file_paths if os.path.basename(file_path) in names_to_filter]\n",
    "print(f\"{file_paths}\")\n",
    "# Dictionary to store titles for each file path\n",
    "file_titles = {}\n",
    "\n",
    "# Populate file_titles dictionary using file_paths list\n",
    "for file_path in file_paths:\n",
    "# Extract file name from file path\n",
    "    file_name = os.path.basename(file_path)\n",
    "\n",
    "# Construct default title based on file name\n",
    "default_title = f\"Title for {file_name}\"\n",
    "\n",
    "# Add entry to file_titles dictionary\n",
    "file_titles[file_path] = default_title\n",
    "\n",
    "statistics.plot_lr_counts(file_paths=file_paths,file_titles=file_titles,results_directory=results_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BINOMIAL TEST\n",
    "output_folder_cluster = \"/home/hubert/TRS-omix_new/python/Pseudomonas_aeruginosa100_results_L100_R100_c0.8/cd-hit-results/fasta_clusters\" # valid name\n",
    "full_seq_final = \"/home/hubert/TRS-omix_new/python/Pseudomonas_aeruginosa100_results_L100_R100_c0.8/final_results/full_sequences_final.fasta\" #unsure\n",
    "df = Stats.create_trs_class_dataframe(output_folder_cluster) # lets work on naming the files as they occur at the end of the combined.py file\n",
    "df = Stats.get_trs_class_totals(df) \n",
    "df\n",
    "\n",
    "#This is used to extract the dataframe with total counts of classes from the full_seqeuences files\n",
    "statistics = Stats()\n",
    "df_full_fasta = statistics.create_lr_counts_dataframe(file_path=full_seq_final)\n",
    "df_full_fasta\n",
    "\n",
    "#Merge the dataframes\n",
    "# def merge_trs_classes_results(df1,df2):\n",
    "#     merged_df = pd.merge(df1,df2, left_index=True,right_index=True,how=\"outer\")\n",
    "#     total_sequences_found = merged_df['Total Count'].sum()/2\n",
    "#     total_sequences_passed = merged_df['Counts'].sum()\n",
    "#     merged_df[\"Proportion_Found\"] = merged_df[\"Total Count\"]/ total_sequences_found\n",
    "#     merged_df[\"Proportion_Passed\"] = merged_df[\"Counts\"]/ total_sequences_passed\n",
    "#     return merged_df\n",
    "\n",
    "merged_df = Stats.merge_trs_classes_results(df_full_fasta,df)\n",
    "\n",
    "\n",
    "final_results_folder = \"/home/hubert/TRS-omix_new/python/Pseudomonas_aeruginosa100_results_L100_R100_c0.8/final_results/\"\n",
    "result_df = Stats.test_binomial_for_classes(merged_df)\n",
    "result_df.index.name = \"Class\"\n",
    "#Function for this now\n",
    "# def save_binom_results(df,folder_path):\n",
    "#     full_results = os.path.join(folder_path,\"binomial_results_full.csv\")\n",
    "#     df.to_csv(full_results,index=True)\n",
    "#     with_counts = df[(df[\"Counts\"] >= 1) & (df[\"Expected Count\"] <= df[\"Counts\"])]\n",
    "#     results_with_counts = os.path.join(folder_path,\"binomial_results_with_counts.csv\")\n",
    "#     with_counts.to_csv(results_with_counts,index=True)\n",
    "#     significant = df[df[\"P-Value\"] <= 0.05]\n",
    "#     results_significant = os.path.join(folder_path,\"binomial_results_significant.csv\")\n",
    "#     significant.to_csv(results_significant,index=True)\n",
    "#     return with_counts,significant\n",
    "\n",
    "with_counts_df, significant_df = Stats.save_binom_results(result_df,final_results_folder)\n",
    "\n",
    "#now let's think of a way to graph it \n",
    "#Probably pie chart ? \n",
    "# def aggregate_df(df,target,treshold):\n",
    "#     df['Grouped'] = df[target].apply(lambda x: x if x / df[target].sum() > treshold else 'Other')\n",
    "#     aggregated_df = df.groupby('Grouped')[target].sum()\n",
    "#     return aggregated_df\n",
    "\n",
    "# aggregated_df = aggregate_df(with_counts_df,\"Counts\",treshold=0.01)\n",
    "\n",
    "# def plot_custom_pie(df, target):\n",
    "#     explode = [0.1 if i == \"L1\" else 0 for i in df.index]\n",
    "#     colors = [\"#ff9999\", \"#66b3ff\", \"#99ff99\", \"#ffcc99\"]\n",
    "\n",
    "\n",
    "    \n",
    "#     df[target].plot(\n",
    "#         kind=\"pie\",\n",
    "#         figsize=(8, 8),\n",
    "#         autopct=lambda pct: f'{pct:.1f}%\\n({pct*df[target].sum()/100:.0f})',\n",
    "#         startangle=90,\n",
    "#         colors=colors,\n",
    "#         explode=explode\n",
    "#     )\n",
    "#     plt.gca().set_aspect(\"equal\")\n",
    "#     plt.title(\"Customized TRS Class Distribution\", fontsize=16)\n",
    "#     plt.ylabel(\"\")  # Remove default y-axis label\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# #plot_custom_pie(with_counts_df,\"Counts\")\n",
    "# aggregated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_filtered_trs_heatmap(df, cluster_sizes, class_type='R'):\n",
    "    \"\"\"\n",
    "    Plots a heatmap of TRS class counts for specific cluster sizes, separated by class type (R or L).\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): DataFrame with TRS classes as rows and cluster sizes as columns.\n",
    "        cluster_sizes (list): List of cluster sizes to include in the heatmap.\n",
    "        class_type (str): 'R' for R classes, 'L' for L classes.\n",
    "    \"\"\"\n",
    "    # Filter rows by class type\n",
    "    filtered_rows = df[df.index.str.startswith(class_type)]\n",
    "\n",
    "    # Filter columns by specified cluster sizes\n",
    "    filtered_columns = [f\"Cluster Size {size}\" for size in cluster_sizes if f\"Cluster Size {size}\" in df.columns]\n",
    "    if not filtered_columns:\n",
    "        print(\"No matching cluster sizes found in DataFrame.\")\n",
    "        return\n",
    "\n",
    "    filtered_df = filtered_rows[filtered_columns]\n",
    "\n",
    "    # Plot the heatmap\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.heatmap(filtered_df, annot=False, cmap=\"viridis\", cbar_kws={'label': 'Frequency'})\n",
    "    plt.title(f\"TRS Class Distribution ({class_type} Classes) for Selected Cluster Sizes\", fontsize=16)\n",
    "    plt.xlabel(\"Cluster Size\", fontsize=12)\n",
    "    plt.ylabel(\"TRS Class\", fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example Usage\n",
    "plot_filtered_trs_heatmap(test, cluster_sizes=[1, 2, 5, 7], class_type='R')\n",
    "#plot_filtered_trs_heatmap(test, cluster_sizes=[1, 2, 5], class_type='L')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_trs_bar(df, trs_classes=None, class_type='R', figsize=(16, 10), bar_width=0.8):\n",
    "    \"\"\"\n",
    "    Plots a bar chart for selected TRS classes across cluster sizes, separated by class type (R or L),\n",
    "    with adjustments for better spacing.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): DataFrame with TRS classes as rows and cluster sizes as columns.\n",
    "        trs_classes (list): List of TRS classes to visualize. If None, shows all of the specified type.\n",
    "        class_type (str): 'R' for R classes, 'L' for L classes.\n",
    "        figsize (tuple): Size of the plot figure.\n",
    "        bar_width (float): Width of the bars in the plot.\n",
    "    \"\"\"\n",
    "    # Filter rows by class type\n",
    "    filtered_df = df[df.index.str.startswith(class_type)]\n",
    "\n",
    "    # Select specific TRS classes if provided\n",
    "    if trs_classes:\n",
    "        filtered_df = filtered_df.loc[trs_classes]\n",
    "\n",
    "    # Transpose for better orientation\n",
    "    filtered_df = filtered_df.transpose()\n",
    "\n",
    "    # Plot the bar chart\n",
    "    ax = filtered_df.plot(\n",
    "        kind=\"bar\",\n",
    "        figsize=figsize,\n",
    "        width=bar_width,\n",
    "        legend=True\n",
    "    )\n",
    "\n",
    "    # Adjust labels and title\n",
    "    plt.title(f\"TRS Class Counts ({class_type} Classes)\", fontsize=16)\n",
    "    plt.xlabel(\"Cluster Size\", fontsize=12)\n",
    "    plt.ylabel(\"Count\", fontsize=12)\n",
    "    plt.xticks(rotation=45, fontsize=10)\n",
    "    plt.legend(title=\"TRS Class\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Example Usage\n",
    "plot_trs_bar(test, class_type='R')\n",
    "plot_trs_bar(test, class_type='L')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_trs_stacked_bar(df, class_type='R'):\n",
    "    \"\"\"\n",
    "    Plots a stacked bar chart of TRS class counts by cluster size, separated by class type (R or L).\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): DataFrame with TRS classes as rows and cluster sizes as columns.\n",
    "        class_type (str): 'R' for R classes, 'L' for L classes.\n",
    "    \"\"\"\n",
    "    # Filter rows by class type\n",
    "    filtered_df = df[df.index.str.startswith(class_type)]\n",
    "\n",
    "    filtered_df.transpose().plot(kind=\"bar\", stacked=True, figsize=(14, 8), cmap=\"tab20\")\n",
    "    plt.title(f\"Stacked TRS Class Counts ({class_type} Classes)\", fontsize=16)\n",
    "    plt.xlabel(\"Cluster Size\", fontsize=12)\n",
    "    plt.ylabel(\"Total Count\", fontsize=12)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend(title=\"TRS Class\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example Usage\n",
    "plot_trs_stacked_bar(test, class_type='R')\n",
    "plot_trs_stacked_bar(test, class_type='L')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_trs_line(df, trs_classes=None, class_type='R'):\n",
    "    \"\"\"\n",
    "    Plots a line chart for selected TRS classes across cluster sizes, separated by class type (R or L).\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): DataFrame with TRS classes as rows and cluster sizes as columns.\n",
    "        trs_classes (list): List of TRS classes to visualize. If None, shows all of the specified type.\n",
    "        class_type (str): 'R' for R classes, 'L' for L classes.\n",
    "    \"\"\"\n",
    "    # Filter rows by class type\n",
    "    filtered_df = df[df.index.str.startswith(class_type)]\n",
    "\n",
    "    # Select specific TRS classes if provided\n",
    "    if trs_classes:\n",
    "        filtered_df = filtered_df.loc[trs_classes]\n",
    "\n",
    "    filtered_df.transpose().plot(kind=\"line\", figsize=(14, 8), marker='o')\n",
    "    plt.title(f\"TRS Class Trends ({class_type} Classes)\", fontsize=16)\n",
    "    plt.xlabel(\"Cluster Size\", fontsize=12)\n",
    "    plt.ylabel(\"Count\", fontsize=12)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend(title=\"TRS Class\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example Usage\n",
    "plot_trs_line(test, class_type='R')\n",
    "plot_trs_line(test, class_type='L')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_trs_pie(df, cluster_size):\n",
    "    \"\"\"\n",
    "    Plots a pie chart of TRS class counts for a specific cluster size.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): DataFrame with TRS classes as rows and cluster sizes as columns.\n",
    "        cluster_size (str): Cluster size column to visualize (e.g., \"Cluster Size 1\").\n",
    "    \"\"\"\n",
    "    if cluster_size not in df.columns:\n",
    "        print(f\"Cluster size {cluster_size} not found in DataFrame.\")\n",
    "        return\n",
    "    \n",
    "    df[cluster_size].plot(kind=\"pie\", figsize=(8, 8), autopct='%1.1f%%', startangle=140)\n",
    "    plt.title(f\"TRS Class Distribution for {cluster_size}\", fontsize=16)\n",
    "    plt.ylabel(\"\")  # Remove y-axis label for pie chart\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example Usage\n",
    "plot_trs_pie(test, cluster_size=\"Cluster Size 4\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Now let's try using cluster files to point out the clusters of given size in which all sequences belong to the same species \n",
    "then write out those clusters into separate .fasta files with names corresponding to species_cluster_size_ID,\n",
    " where ID is taken from initial file used for cluster filtering'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder_cluster = \"/home/hubert/TRS-omix_new/python/viruses_results_L100_R100_c0.8/cd-hit-results/fasta_clusters\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def find_single_species_clusters(folder_path, cluster_size=None):\n",
    "    # If cluster_size is provided, restrict analysis to the specific folder\n",
    "    if cluster_size:\n",
    "        folder_path = os.path.join(folder_path, f\"cluster_size_{cluster_size}\")\n",
    "        if not os.path.exists(folder_path):\n",
    "            print(f\"Folder for cluster size {cluster_size} does not exist.\")\n",
    "            return\n",
    "    \n",
    "    species_results = []\n",
    "    \n",
    "    # Define files to scan based on whether cluster_size is provided\n",
    "    if cluster_size:\n",
    "        # Analyze files directly in the specified folder\n",
    "        files_to_scan = [\n",
    "            (folder_path, file) for file in os.listdir(folder_path) if file.endswith(\".fasta\")\n",
    "        ]\n",
    "    else:\n",
    "        # Analyze all files in subfolders\n",
    "        files_to_scan = []\n",
    "        for subfolder in os.listdir(folder_path):\n",
    "            subfolder_path = os.path.join(folder_path, subfolder)\n",
    "            if not os.path.isdir(subfolder_path):  # Ignore files directly in folder_path\n",
    "                continue\n",
    "            files_to_scan.extend(\n",
    "                [(subfolder_path, file) for file in os.listdir(subfolder_path) if file.endswith(\".fasta\")]\n",
    "            )\n",
    "\n",
    "    # Process each file\n",
    "    for folder, file_name in files_to_scan:\n",
    "        file_path = os.path.join(folder, file_name)\n",
    "        with open(file_path, \"r\") as f:\n",
    "            species_set = set()\n",
    "            for line in f:\n",
    "                if line.startswith(\">\"):\n",
    "                    # Extract species name from header\n",
    "                    species_parts = line.split()[0].split(\"_\")[:-2]\n",
    "                    species_name = \"_\".join(species_parts)\n",
    "                    species_set.add(species_name)\n",
    "            if len(species_set) == 1:\n",
    "                species_name = species_set.pop()\n",
    "                print(f\"All sequences in {file_name} (in {folder}) are from the same species: {species_name}\")\n",
    "                species_results.append((folder, file_name, species_name))\n",
    "    \n",
    "    # Return results\n",
    "    return species_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = find_single_species_clusters(output_folder_cluster,cluster_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TRS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
